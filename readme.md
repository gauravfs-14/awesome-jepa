# Awesome JEPA - Joint Embedding Predictive Architecture

![Awesome](https://awesome.re/badge.svg)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
![GitHub Contributors](https://img.shields.io/github/contributors/gauravfs-14/awesome-jepa.svg)
![GitHub Last Commit](https://img.shields.io/github/last-commit/gauravfs-14/awesome-jepa.svg)
[![GitHub Stars](https://img.shields.io/github/stars/gauravfs-14/awesome-jepa.svg?style=social)](https://github.com/gauravfs-14/awesome-jepa)
![GitHub Forks](https://img.shields.io/github/forks/gauravfs-14/awesome-jepa.svg)

A carefully curated collection of high-quality tools, libraries, research papers, projects, and tutorials centered around Joint Embedding Predictive Architecture (JEPA) â€” a self-supervised learning paradigm introduced by Yann LeCun and Meta AI that learns representations by predicting representations of the future from representations of the present, without reconstructing pixels or tokens. This repository serves as a comprehensive, well-organized knowledge hub for researchers and developers exploring the next frontier of self-supervised learning and representation learning.

JEPA represents a fundamental shift in how AI systems learn representations. Unlike traditional generative models that reconstruct inputs, JEPA learns to predict abstract representations of the future state of the world from abstract representations of the present. This approach enables more efficient learning, better generalization, and the ability to handle complex, high-dimensional data without the computational overhead of pixel-level reconstruction.

To keep the community up-to-date with the latest developments, this repository is continuously enriched with newly published JEPA-related papers, real-world use cases, and open-source implementations. From foundational architectures to advanced variants like Hierarchical JEPA (H-JEPA) and applications in vision, language, and multimodal learning, the collection aims to highlight both foundational ideas and emerging best practices.

> [!NOTE]
> ðŸ“¢ **Announcement:** Our paper is now available on [SSRN](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5772122)!  
> **Title:** *A Survey on Joint Embedding Predictive Architectures and World Models*  
> If you find this paper interesting, please consider citing our work. Thank you for your support!

```bibtex
@article{brotee2025survey,
  title={A Survey on Joint Embedding Predictive Architectures and World Models},
  author={Brotee, Shamyo and Chhetri, Gaurab and Polock, Sazzad Bin Bashar and Bellamkonda, Venkata Surya and Rafe, Amir and Das, Subasish},
  journal={Available at SSRN 5772122},
  year={2025}
}
```

Whether you are building self-supervised learning systems, researching representation learning, or experimenting with predictive architectures for vision, language, or multimodal tasks, this resource offers a centralized, evolving platform to explore the powerful and expanding universe of JEPA-based systems.

## Last Updated
December 24, 2025 at 01:57:47 AM UTC


## Theorem

## Papers (40)
- [TEM Agent: enhancing transmission electron microscopy (TEM) with modern AI tools](https://arxiv.org/abs/2511.08819)
- [ORCHID: Orchestrated Retrieval-Augmented Classification with Human-in-the-Loop Intelligent Decision-Making for High-Risk Property](https://arxiv.org/abs/2511.04956)
- [Securing AI Agent Execution](https://arxiv.org/abs/2510.21236)
- [NetMCP: Network-Aware Model Context Protocol Platform for LLM Capability Extension](https://arxiv.org/abs/2510.13467)
- [LLM\times\timesMapReduce-V3: Enabling Interactive In-Depth Survey Generation through a MCP-Driven Hierarchically Modular Agent System](https://arxiv.org/abs/2510.10890)
- [AniME: Adaptive Multi-Agent Planning for Long Animation Generation](https://arxiv.org/abs/2508.18781)
- [Towards Agentic OS: An LLM Agent Framework for Linux Schedulers](https://arxiv.org/abs/2509.01245)
- [Model Context Protocol for Vision Systems: Audit, Security, and Protocol Extensions](https://arxiv.org/abs/2509.22814)
- [Agentic-AI Healthcare: Multilingual, Privacy-First Framework with MCP Agents](https://arxiv.org/abs/2510.02325)
- [IoT-MCP: Bridging LLMs and IoT Systems Through Model Context Protocol](https://arxiv.org/abs/2510.01260)
- [XARP Tools: An Extended Reality Platform for Humans and AI Agents](https://arxiv.org/abs/2508.04108)
- [Dynamic ReAct: Scalable Tool Selection for Large-Scale MCP Environments](https://arxiv.org/abs/2509.20386)
- [Tool Preferences in Agentic LLMs are Unreliable](https://arxiv.org/abs/2505.18135)
- [EHR-MCP: Real-world Evaluation of Clinical Information Retrieval by Large Language Models via Model Context Protocol](https://arxiv.org/abs/2509.15957)
- [Beyond the Protocol: Unveiling Attack Vectors in the Model Context Protocol (MCP) Ecosystem](https://arxiv.org/abs/2506.02040)
- [MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World Tasks via MCP Servers](https://arxiv.org/abs/2508.20453)
- [Help or Hurdle? Rethinking Model Context Protocol-Augmented Large Language Models](https://arxiv.org/abs/2508.12566)
- [MCP2OSC: Parametric Control by Natural Language](https://arxiv.org/abs/2508.10414)
- [Magentic-UI: Towards Human-in-the-loop Agentic Systems](https://arxiv.org/abs/2507.22358)
- [MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations](https://arxiv.org/abs/2507.21428)
- [Gradientsys: A Multi-Agent LLM Scheduler with ReAct Orchestration](https://arxiv.org/abs/2507.06520)
- [Model Context Protocol (MCP) at First Glance: Studying the Security and Maintainability of MCP Servers](https://arxiv.org/abs/2506.13538)
- [We Should Identify and Mitigate Third-Party Safety Risks in MCP-Powered Agent Systems](https://arxiv.org/abs/2506.13666)
- [Agentic Semantic Control for Autonomous Wireless Space Networks: Extending Space-O-RAN with MCP-Driven Distributed Intelligence](https://arxiv.org/abs/2506.10925)
- [Beyond Formal Semantics for Capabilities and Skills: Model Context Protocol in Manufacturing](https://arxiv.org/abs/2506.11180)
- [ETDI: Mitigating Tool Squatting and Rug Pull Attacks in Model Context Protocol (MCP) by using OAuth-Enhanced Tool Definitions and Policy-Based Access Control](https://arxiv.org/abs/2506.01333)
- [Mind the Metrics: Patterns for Telemetry-Aware In-IDE AI Application Development using the Model Context Protocol (MCP)](https://arxiv.org/abs/2506.11019)
- [Enterprise-Grade Security for the Model Context Protocol (MCP): Frameworks and Mitigation Strategies](https://arxiv.org/abs/2504.08623)
- [Securing GenAI Multi-Agent Systems Against Tool Squatting: A Zero Trust Registry-Based Approach](https://arxiv.org/abs/2504.19951)
- [MCP Bridge: A Lightweight, LLM-Agnostic RESTful Proxy for Model Context Protocol Servers](https://arxiv.org/abs/2504.08999)
- [MCP Safety Audit: LLMs with the Model Context Protocol Allow Major Security Exploits](https://arxiv.org/abs/2504.03767)
- [Hiding in the AI Traffic: Abusing MCP for LLM-Powered Agentic Red Teaming](https://arxiv.org/abs/2511.15998)
- [Securing the Model Context Protocol (MCP): Risks, Controls, and Governance](https://arxiv.org/abs/2511.20920)
- [MCP vs RAG vs NLWeb vs HTML: A Comparison of the Effectiveness and Efficiency of Different Agent Interfaces to the Web (Technical Report)](https://arxiv.org/abs/2511.23281)
- [PaperDebugger: A Plugin-Based Multi-Agent System for In-Editor Academic Writing, Review, and Editing](https://arxiv.org/abs/2512.02589)
- [Leveraging Large Language Models to Bridge On-chain and Off-chain Transparency in Stablecoins](https://arxiv.org/abs/2512.02418)
- [LeechHijack: Covert Computational Resource Exploitation in Intelligent Agent Systems](https://arxiv.org/abs/2512.02321)
- [Benchmark for Planning and Control with Large Language Model Agents: Blocksworld with Model Context Protocol](https://arxiv.org/abs/2512.03955)
- [AgentBay: A Hybrid Interaction Sandbox for Seamless Human-AI Intervention in Agentic Systems](https://arxiv.org/abs/2512.04367)
- [RoboNeuron: A Modular Framework Linking Foundation Models and ROS for Embodied AI](https://arxiv.org/abs/2512.10394)


## Library

## Tutorial

### Written Tutorials

### Video Tutorials

## Contributing

We welcome contributions to this repository! If you have a resource that you believe should be included, please submit a pull request or open an issue. Contributions can include:

- New libraries or tools related to JEPA.
- Tutorials or guides that help users understand and implement JEPA.
- Research papers that advance the field of JEPA and self-supervised learning.
- Any other resources that you find valuable for the community

## How to Contribute

1. Fork the repository.
2. Create a new branch for your changes.
3. Make your changes and commit them with a clear message.
4. Push your changes to your forked repository.
5. Submit a pull request to the main repository.

Before contributing, take a look at the existing resources to avoid duplicates.

## License

This repository is licensed under the [Creative Commons Attribution 4.0 International License (CC BY 4.0)](LICENSE). You are free to share and adapt the material, provided you give appropriate credit, link to the license, and indicate if changes were made.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=gauravfs-14/awesome-jepa)](https://star-history.com/#gauravfs-14/awesome-jepa&Date)
