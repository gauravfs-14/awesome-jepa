# Awesome JEPA - Joint Embedding Predictive Architecture

![Awesome](https://awesome.re/badge.svg)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
![GitHub Contributors](https://img.shields.io/github/contributors/gauravfs-14/awesome-jepa.svg)
![GitHub Last Commit](https://img.shields.io/github/last-commit/gauravfs-14/awesome-jepa.svg)
[![GitHub Stars](https://img.shields.io/github/stars/gauravfs-14/awesome-jepa.svg?style=social)](https://github.com/gauravfs-14/awesome-jepa)
![GitHub Forks](https://img.shields.io/github/forks/gauravfs-14/awesome-jepa.svg)

A carefully curated collection of high-quality tools, libraries, research papers, projects, and tutorials centered around Joint Embedding Predictive Architecture (JEPA) â€” a self-supervised learning paradigm introduced by Yann LeCun and Meta AI that learns representations by predicting representations of the future from representations of the present, without reconstructing pixels or tokens. This repository serves as a comprehensive, well-organized knowledge hub for researchers and developers exploring the next frontier of self-supervised learning and representation learning.

JEPA represents a fundamental shift in how AI systems learn representations. Unlike traditional generative models that reconstruct inputs, JEPA learns to predict abstract representations of the future state of the world from abstract representations of the present. This approach enables more efficient learning, better generalization, and the ability to handle complex, high-dimensional data without the computational overhead of pixel-level reconstruction.

To keep the community up-to-date with the latest developments, this repository is continuously enriched with newly published JEPA-related papers, real-world use cases, and open-source implementations. From foundational architectures to advanced variants like Hierarchical JEPA (H-JEPA) and applications in vision, language, and multimodal learning, the collection aims to highlight both foundational ideas and emerging best practices.

> [!NOTE]
> ðŸ“¢ **Announcement:** Our paper is now available on [SSRN](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5772122)!  
> **Title:** *A Survey on Joint Embedding Predictive Architectures and World Models*  
> If you find this paper interesting, please consider citing our work. Thank you for your support!

```bibtex
@article{brotee2025survey,
  title={A Survey on Joint Embedding Predictive Architectures and World Models},
  author={Brotee, Shamyo and Chhetri, Gaurab and Polock, Sazzad Bin Bashar and Bellamkonda, Venkata Surya and Rafe, Amir and Das, Subasish},
  journal={Available at SSRN 5772122},
  year={2025}
}
```

Whether you are building self-supervised learning systems, researching representation learning, or experimenting with predictive architectures for vision, language, or multimodal tasks, this resource offers a centralized, evolving platform to explore the powerful and expanding universe of JEPA-based systems.

## Last Updated
February 5, 2026 at 02:30:29 AM UTC


## Theorem

## Papers (68)
- [PhysVideoGenerator: Towards Physically Aware Video Generation via Latent Physics Guidance](https://arxiv.org/abs/2601.03665)
- [HanoiWorld : A Joint Embedding Predictive Architecture BasedWorld Model for Autonomous Vehicle Controller](https://arxiv.org/abs/2601.01577)
- [BERT-JEPA: Reorganizing CLS Embeddings for Language-Invariant Semantics](https://arxiv.org/abs/2601.00366)
- [Value-guided action planning with JEPA world models](https://arxiv.org/abs/2601.00844)
- [JEPA-Reasoner: Decoupling Latent Reasoning from Token Generation](https://arxiv.org/abs/2512.19171)
- [KerJEPA: Kernel Discrepancies for Euclidean Self-Supervised Learning](https://arxiv.org/abs/2512.19605)
- [VL-JEPA: Joint Embedding Predictive Architecture for Vision-language](https://arxiv.org/abs/2512.10942)
- [JEPA as a Neural Tokenizer: Learning Robust Speech Representations with Density Adaptive Attention](https://arxiv.org/abs/2512.07168)
- [Opinion: Learning Intuitive Physics May Require More than Visual Data](https://arxiv.org/abs/2512.06232)
- [Tokenizing Buildings: A Transformer for Layout Synthesis](https://arxiv.org/abs/2512.04832)
- [EnzyCLIP: A Cross-Attention Dual Encoder Framework with Contrastive Learning for Predicting Enzyme Kinetic Constants](https://arxiv.org/abs/2512.00379)
- [Health system learning achieves generalist neuroimaging models](https://arxiv.org/abs/2511.18640)
- [CrossJEPA: Cross-Modal Joint-Embedding Predictive Architecture for Efficient 3D Representation Learning from 2D Images](https://arxiv.org/abs/2511.18424)
- [DSeq-JEPA: Discriminative Sequential Joint-Embedding Predictive Architecture](https://arxiv.org/abs/2511.17354)
- [POMA-3D: The Point Map Way to 3D Scene Understanding](https://arxiv.org/abs/2511.16567)
- [Beyond Generative AI: World Models for Clinical Prediction, Counterfactuals, and Planning](https://arxiv.org/abs/2511.16333)
- [PI-NAIM: Path-Integrated Neural Adaptive Imputation Model](https://arxiv.org/abs/2511.11908)
- [LeJEPA: Provable and Scalable Self-Supervised Learning Without the Heuristics](https://arxiv.org/abs/2511.08544)
- [Multi-Joint Physics-Informed Deep Learning Framework for Time-Efficient Inverse Dynamics](https://arxiv.org/abs/2511.10878)
- [Koopman Invariants as Drivers of Emergent Time-Series Clustering in Joint-Embedding Predictive Architectures](https://arxiv.org/abs/2511.09783)
- [TransactionGPT](https://arxiv.org/abs/2511.08939)
- [WavJEPA: Semantic learning unlocks robust audio foundation models for raw waveforms](https://arxiv.org/abs/2509.23238)
- [Learning from Reward-Free Offline Data: A Case for Planning with Latent Dynamics Models](https://arxiv.org/abs/2502.14819)
- [CSU-PCAST: A Dual-Branch Transformer Framework for medium-range ensemble Precipitation Forecasting](https://arxiv.org/abs/2510.20769)
- [Improving the Physics of Video Generation with VJEPA-2 Reward Signal](https://arxiv.org/abs/2510.21840)
- [DINO-CVA: A Multimodal Goal-Conditioned Vision-to-Action Model for Autonomous Catheter Navigation](https://arxiv.org/abs/2510.17038)
- [Why and How Auxiliary Tasks Improve JEPA Representations](https://arxiv.org/abs/2509.12249)
- [Valeo Near-Field: a novel dataset for pedestrian intent detection](https://arxiv.org/abs/2510.15673)
- [LLM-JEPA: Large Language Models Meet Joint Embedding Predictive Architectures](https://arxiv.org/abs/2509.14252)
- [Gaussian Embeddings: How JEPAs Secretly Learn Your Data Density](https://arxiv.org/abs/2510.05949)
- [Self-Supervised Representation Learning with Joint Embedding Predictive Architecture for Automotive LiDAR Object Detection](https://arxiv.org/abs/2501.04969)
- [JEPA-T: Joint-Embedding Predictive Architecture with Text Fusion for Image Generation](https://arxiv.org/abs/2510.00974)
- [Joint Embeddings Go Temporal](https://arxiv.org/abs/2509.25449)
- [Rethinking JEPA: Compute-Efficient Video SSL with Frozen Teachers](https://arxiv.org/abs/2509.24317)
- [MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid Vision Tokenizer](https://arxiv.org/abs/2509.16197)
- [Self-supervised learning of imaging and clinical signatures using a multimodal joint-embedding predictive architecture](https://arxiv.org/abs/2509.15470)
- [EgoAgent: A Joint Predictive Agent Model in Egocentric Worlds](https://arxiv.org/abs/2502.05857)
- [MuMTAffect: A Multimodal Multitask Affective Framework for Personality and Emotion Recognition from Physiological Signals](https://arxiv.org/abs/2509.04254)
- [Predict, Cluster, Refine: A Joint Embedding Predictive Self-Supervised Framework for Graph Representation Learning](https://arxiv.org/abs/2502.01684)
- [Learning State-Space Models of Dynamic Systems from Arbitrary Data using Joint Embedding Predictive Architectures](https://arxiv.org/abs/2508.10489)
- [JEPA4Rec: Learning Effective Language Representations for Sequential Recommendation via Joint Embedding Predictive Architecture](https://arxiv.org/abs/2504.10512)
- [Elucidating the Role of Feature Normalization in IJEPA](https://arxiv.org/abs/2508.02829)
- [TrajFlow: A Generative Framework for Occupancy Density Estimation Using Normalizing Flows](https://arxiv.org/abs/2501.14266)
- [CLIPTime: Time-Aware Multimodal Representation Learning from Images and Text](https://arxiv.org/abs/2508.00447)
- [PatchTraj: Unified Time-Frequency Representation Learning via Dynamic Patches for Trajectory Prediction](https://arxiv.org/abs/2507.19119)
- [Speaking in Words, Thinking in Logic: A Dual-Process Framework in QA Systems](https://arxiv.org/abs/2507.20491)
- [BadHMP: Backdoor Attack against Human Motion Prediction](https://arxiv.org/abs/2409.19638)
- [Improving Joint Embedding Predictive Architecture with Diffusion Noise](https://arxiv.org/abs/2507.15216)
- [From Video to EEG: Adapting Joint Embedding Predictive Architecture to Uncover Visual Concepts in Brain Signal Analysis](https://arxiv.org/abs/2507.03633)
- [MCST-Mamba: Multivariate Mamba-Based Model for Traffic Prediction](https://arxiv.org/abs/2507.03927)
- [seq-JEPA: Autoregressive Predictive Learning of Invariant-Equivariant World Models](https://arxiv.org/abs/2505.03176)
- [Conditional Normalizing Flows for Forward and Backward Joint State and Parameter Estimation](https://arxiv.org/abs/2601.07013)
- [Akasha 2: Hamiltonian State Space Duality and Visual-Language Joint Embedding Predictive Architectur](https://arxiv.org/abs/2601.06212)
- [Video Joint-Embedding Predictive Architectures for Facial Expression Recognition](https://arxiv.org/abs/2601.09524)
- [VJEPA: Variational Joint Embedding Predictive Architectures as Probabilistic World Models](https://arxiv.org/abs/2601.14354)
- [RadJEPA: Radiology Encoder for Chest X-Rays via Joint Embedding Predictive Architecture](https://arxiv.org/abs/2601.15891)
- [Spatiotemporal Semantic V2X Framework for Cooperative Collision Prediction](https://arxiv.org/abs/2601.17216)
- [WirelessJEPA: A Multi-Antenna Foundation Model using Spatio-temporal Wireless Latent Predictions](https://arxiv.org/abs/2601.20190)
- [A Latent Space Framework for Modeling Transient Engine Emissions Using Joint Embedding Predictive Architectures](https://arxiv.org/abs/2601.19822)
- [The Patient is not a Moving Document: A World Model Training Paradigm for Longitudinal EHR](https://arxiv.org/abs/2601.22128)
- [Drive-JEPA: Video JEPA Meets Multimodal Trajectory Distillation for End-to-End Driving](https://arxiv.org/abs/2601.22032)
- [JTok: On Token Embedding as another Axis of Scaling Law via Joint Token Self-modulation](https://arxiv.org/abs/2602.00800)
- [Cell-JEPA: Latent Representation Learning for Single-Cell Transcriptomics](https://arxiv.org/abs/2602.02093)
- [CryoLVM: Self-supervised Learning from Cryo-EM Density Maps with Large Vision Models](https://arxiv.org/abs/2602.02620)
- [Bayesian Integration of Nonlinear Incomplete Clinical Data](https://arxiv.org/abs/2602.01924)
- [Rectified LpJEPA: Joint-Embedding Predictive Architectures with Sparse and Maximum-Entropy Representations](https://arxiv.org/abs/2602.01456)
- [MTS-JEPA: Multi-Resolution Joint-Embedding Predictive Architecture for Time-Series Anomaly Prediction](https://arxiv.org/abs/2602.04643)
- [A Lightweight Library for Energy-Based Joint-Embedding Predictive Architectures](https://arxiv.org/abs/2602.03604)


## Library

## Tutorial

### Written Tutorials

### Video Tutorials

## Contributing

We welcome contributions to this repository! If you have a resource that you believe should be included, please submit a pull request or open an issue. Contributions can include:

- New libraries or tools related to JEPA.
- Tutorials or guides that help users understand and implement JEPA.
- Research papers that advance the field of JEPA and self-supervised learning.
- Any other resources that you find valuable for the community

## How to Contribute

1. Fork the repository.
2. Create a new branch for your changes.
3. Make your changes and commit them with a clear message.
4. Push your changes to your forked repository.
5. Submit a pull request to the main repository.

Before contributing, take a look at the existing resources to avoid duplicates.

## License

This repository is licensed under the [Creative Commons Attribution 4.0 International License (CC BY 4.0)](LICENSE). You are free to share and adapt the material, provided you give appropriate credit, link to the license, and indicate if changes were made.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=gauravfs-14/awesome-jepa)](https://star-history.com/#gauravfs-14/awesome-jepa&Date)
